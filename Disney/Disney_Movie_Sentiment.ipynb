{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disney Movie Sentiment Effect\n",
    "This notebook aims to predict the sentiment of upcoming Disney movies based on character roles and viewer sentiment data. The workflow includes merging datasets, training a machine learning model, and making predictions on new datasets.\n",
    "\n",
    "The purpose of this experiment is to classify characters and analyze their impact on viewers' emotional responses, you can use a combination of personality traits, narrative roles, and archetypes. Here are 10 distinct character types that could influence emotional responses:\n",
    "\n",
    "1. The Hero/Protagonist\n",
    "Description: Central character driving the story, often evoking empathy or admiration.\n",
    "Effect: A poorly written or unrelatable protagonist can lead to disengagement.\n",
    "Examples: Simba (The Lion King), Moana (Moana).\n",
    "2. The Villain/Antagonist\n",
    "Description: Opposes the hero, often introducing conflict and tension.\n",
    "Effect: An overly predictable or weak villain can reduce emotional stakes.\n",
    "Examples: Scar (The Lion King), Ursula (The Little Mermaid).\n",
    "3. The Comic Relief\n",
    "Description: Provides humor and light-hearted moments.\n",
    "Effect: Excessive or inappropriate humor can disrupt the emotional tone.\n",
    "Examples: Olaf (Frozen), Mushu (Mulan).\n",
    "4. The Sidekick\n",
    "Description: Supports the hero, often offering loyalty and advice.\n",
    "Effect: A sidekick who is annoying or lacks depth can frustrate viewers.\n",
    "Examples: Timon and Pumbaa (The Lion King), Dory (Finding Nemo).\n",
    "5. The Mentor\n",
    "Description: Offers wisdom or guidance to the hero, often inspiring emotional connections.\n",
    "Effect: An unconvincing or overly preachy mentor can feel insincere.\n",
    "Examples: Mufasa (The Lion King), Grandmother Willow (Pocahontas).\n",
    "6. The Love Interest\n",
    "Description: Provides romantic tension or emotional stakes for the protagonist.\n",
    "Effect: A shallow or forced love interest can detract from the story's emotional weight.\n",
    "Examples: Belle (Beauty and the Beast), Jasmine (Aladdin).\n",
    "7. The Anti-Hero\n",
    "Description: A morally complex character who may work against traditional values.\n",
    "Effect: If poorly developed, they can confuse or alienate viewers.\n",
    "Examples: Megamind (Megamind), Jack Sparrow (Pirates of the Caribbean).\n",
    "8. The Tragic Character\n",
    "Description: Suffers personal loss or misfortune, evoking pity or sadness.\n",
    "Effect: Overuse of tragedy or melodrama can feel manipulative.\n",
    "Examples: Bambi's mother (Bambi), Bing Bong (Inside Out).\n",
    "9. The Villain-Turned-Ally\n",
    "Description: Starts as an antagonist but changes sides due to personal growth or redemption.\n",
    "Effect: A poorly justified redemption arc can feel hollow or unsatisfying.\n",
    "Examples: Stitch (Lilo & Stitch), Kuzco (The Emperor’s New Groove).\n",
    "10. The Background Ensemble\n",
    "Description: Minor characters who add flavor but do not drive the main plot.\n",
    "Effect: Overly distracting or poorly integrated background characters can disrupt immersion.\n",
    "Examples: The hyenas (The Lion King), The trolls (Frozen).\n",
    "Additional Subtypes to Consider\n",
    "The Innocent Child: Evokes purity or vulnerability (e.g., Boo in Monsters, Inc.).\n",
    "The Animal Companion: Adds charm or relatability (e.g., Maximus in Tangled).\n",
    "The Trickster: Causes chaos, often with ambiguous motives (e.g., Loki in Marvel movies).\n",
    "\n",
    "\n",
    "## Experiment Setup\n",
    "\n",
    "# Problem Definition\n",
    "Predict Future Disney Movie Sentiment Based on Scripted Character Data.\n",
    "\n",
    "## Step 1: Data Collection:\n",
    "\n",
    "#### Gather viewer feedback on emotional responses to movies with identified character types.\n",
    "Collect metadata on characters’ roles, screen time, and development.\n",
    "Feature Engineering:\n",
    "\n",
    "#### Categorize characters into these 10 types.\n",
    "Include attributes like personality traits, narrative impact, and audience reactions.\n",
    "Analysis:\n",
    "\n",
    "#### Use sentiment analysis on reviews or surveys to measure emotional responses.\n",
    "Apply machine learning models to determine correlations between character types and negative responses.\n",
    "Insights:\n",
    "\n",
    "#### Identify which types consistently evoke negative reactions.\n",
    "Determine if combinations of character types exacerbate or mitigate negative effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load and Explore Datasets\n",
    "Load datasets and examine the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewer Sentiment Data:\n",
      "   Character Name   Movie Title          Role  Sentiment Score\n",
      "95         Marlin  Finding Nemo   Protagonist                9\n",
      "96           Dory  Finding Nemo  Comic Relief                9\n",
      "97           Nemo  Finding Nemo    Supportive                9\n",
      "98          Bruce  Finding Nemo    Antagonist                6\n",
      "99          Crush  Finding Nemo  Comic Relief                8\n",
      "\n",
      "Character Roles Data:\n",
      "   Character Name          Role\n",
      "95         Marlin   Protagonist\n",
      "96           Dory  Comic Relief\n",
      "97           Nemo    Supportive\n",
      "98          Bruce    Antagonist\n",
      "99          Crush  Comic Relief\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load and Explore Datasets\n",
    "# Load the character viewer sentiment dataset\n",
    "viewer_sentiment_path = 'character_sentiment_scores.csv'  # Replace with your file path\n",
    "character_roles_path = 'character_roles.csv'  # Replace with your file path\n",
    "viewer_sentiment_data = pd.read_csv(viewer_sentiment_path)\n",
    "character_roles_data = pd.read_csv(character_roles_path)\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"Viewer Sentiment Data:\")\n",
    "print(viewer_sentiment_data.tail())\n",
    "\n",
    "print(\"\\nCharacter Roles Data:\")\n",
    "print(character_roles_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Merge Datasets\n",
    "Combine the datasets for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Data:\n",
      "   Character Name Movie Title       Role_x  Sentiment Score       Role_y  \\\n",
      "0  Luke Skywalker   Star Wars  Protagonist                9  Protagonist   \n",
      "1     Darth Vader   Star Wars   Antagonist                8   Antagonist   \n",
      "2     Leia Organa   Star Wars   Supportive                9   Supportive   \n",
      "3        Han Solo   Star Wars  Protagonist                9  Protagonist   \n",
      "4            Yoda   Star Wars       Mentor               10       Mentor   \n",
      "\n",
      "  Sentiment Label  \n",
      "0        Positive  \n",
      "1        Positive  \n",
      "2        Positive  \n",
      "3        Positive  \n",
      "4        Positive  \n",
      "\n",
      "Merged Data:\n",
      "    Character Name   Movie Title        Role_x  Sentiment Score        Role_y  \\\n",
      "0   Luke Skywalker     Star Wars   Protagonist                9   Protagonist   \n",
      "1      Darth Vader     Star Wars    Antagonist                8    Antagonist   \n",
      "2      Leia Organa     Star Wars    Supportive                9    Supportive   \n",
      "3         Han Solo     Star Wars   Protagonist                9   Protagonist   \n",
      "4             Yoda     Star Wars        Mentor               10        Mentor   \n",
      "..             ...           ...           ...              ...           ...   \n",
      "95          Marlin  Finding Nemo   Protagonist                9   Protagonist   \n",
      "96            Dory  Finding Nemo  Comic Relief                9  Comic Relief   \n",
      "97            Nemo  Finding Nemo    Supportive                9    Supportive   \n",
      "98           Bruce  Finding Nemo    Antagonist                6    Antagonist   \n",
      "99           Crush  Finding Nemo  Comic Relief                8  Comic Relief   \n",
      "\n",
      "   Sentiment Label  \n",
      "0         Positive  \n",
      "1         Positive  \n",
      "2         Positive  \n",
      "3         Positive  \n",
      "4         Positive  \n",
      "..             ...  \n",
      "95        Positive  \n",
      "96        Positive  \n",
      "97        Positive  \n",
      "98         Neutral  \n",
      "99        Positive  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Merge Datasets\n",
    "# Merge the datasets on a common key, such as 'Character Name'\n",
    "#merged_data = pd.merge(viewer_sentiment_data, character_roles_data, on='Character Name', how='inner')\n",
    "\n",
    "# Display the merged dataset\n",
    "print(\"\\nMerged Data:\")\n",
    "print(merged_data.head())\n",
    "\n",
    "# Step 5: Data Preprocessing\n",
    "# Encode categorical features and prepare the data for training\n",
    "merged_data['Sentiment Label'] = merged_data['Sentiment Score'].map({\n",
    "    10: \"Positive\",\n",
    "    9: \"Positive\",\n",
    "    8: \"Positive\",\n",
    "    7: \"Positive\",\n",
    "    6: \"Neutral\",\n",
    "    5: \"Neutral\",\n",
    "    5: \"Neutral\",\n",
    "    4: \"Neutral\",\n",
    "    3: \"Negative\",\n",
    "    2: \"Negative\",\n",
    "    1: \"Negative\"\n",
    "})\n",
    "\n",
    "\n",
    "#merged_data = merged_data.drop(['Sentiment Label'], axis=1)\n",
    "features = merged_data.drop(['Sentiment Score'], axis=1)\n",
    "#labels = merged_data['Role']\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "features = pd.get_dummies(features)\n",
    "\n",
    "print(\"\\nMerged Data:\")\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "             Avengers       0.00      0.00      0.00         1\n",
      "                 Cars       0.00      0.00      0.00         1\n",
      "                 Coco       1.00      1.00      1.00         1\n",
      "         Harry Potter       1.00      1.00      1.00         2\n",
      "           Inside Out       1.00      1.00      1.00         1\n",
      "             Iron Man       0.00      0.00      0.00         1\n",
      "                Shrek       1.00      1.00      1.00         1\n",
      "              Shrek 2       0.00      0.00      0.00         0\n",
      "            Star Wars       1.00      1.00      1.00         3\n",
      "              Tangled       0.00      0.00      0.00         0\n",
      "      The Dark Knight       0.00      0.00      0.00         1\n",
      "      The Incredibles       1.00      1.00      1.00         1\n",
      "        The Lion King       1.00      1.00      1.00         2\n",
      "   The Little Mermaid       1.00      1.00      1.00         1\n",
      "The Lord of the Rings       1.00      1.00      1.00         1\n",
      "                 Thor       0.00      0.00      0.00         0\n",
      "                   Up       1.00      0.50      0.67         2\n",
      "               WALL-E       1.00      1.00      1.00         1\n",
      "\n",
      "             accuracy                           0.75        20\n",
      "            macro avg       0.61      0.58      0.59        20\n",
      "         weighted avg       0.80      0.75      0.77        20\n",
      "\n",
      "Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kfessler/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kfessler/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kfessler/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kfessler/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kfessler/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kfessler/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Train the Model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Evaluate the Model\n",
    "predictions = model.predict(X_test)\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Plot Characteristics vs. Sentiment\n",
    "# Visualize patterns and correlations\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(4, 28))\n",
    "sns.scatterplot(\n",
    "    data=merged_data,\n",
    "    y='Character Name',\n",
    "    x='Sentiment Score',\n",
    "    hue='Sentiment Score',\n",
    "    #palette={'Positive': 'green', 'Negative': 'red', 'Neutral': 'blue'},\n",
    "    s=100\n",
    ")\n",
    "plt.title(\"Character Viewer Sentiment\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Character Name\")\n",
    "plt.xticks()\n",
    "plt.legend(title=\"Viewer Sentiment\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Sentiment for New Characters:\n",
      "   Character Name_Albus Dumbledore  Character Name_Anger  Character Name_Anna  \\\n",
      "0                                0                     0                    0   \n",
      "1                                0                     0                    0   \n",
      "2                                0                     0                    0   \n",
      "\n",
      "   Character Name_Anton Ego  Character Name_Aragorn  Character Name_Ariel  \\\n",
      "0                         0                       0                     0   \n",
      "1                         0                       0                     0   \n",
      "2                         0                       0                     0   \n",
      "\n",
      "   Character Name_Beast  Character Name_Belle  Character Name_Bruce  \\\n",
      "0                     0                     0                     0   \n",
      "1                     0                     0                     0   \n",
      "2                     0                     0                     0   \n",
      "\n",
      "   Character Name_Bruce Banner  ...  Role_x_Supportive  Role_y_Antagonist  \\\n",
      "0                            0  ...                  0                  0   \n",
      "1                            0  ...                  0                  0   \n",
      "2                            0  ...                  0                  0   \n",
      "\n",
      "   Role_y_Comic Relief  Role_y_Mentor  Role_y_Neutral  Role_y_Protagonist  \\\n",
      "0                    0              0               0                   0   \n",
      "1                    0              0               0                   0   \n",
      "2                    0              0               0                   0   \n",
      "\n",
      "   Role_y_Supportive  Sentiment Label_Neutral  Sentiment Label_Positive  \\\n",
      "0                  0                        0                         0   \n",
      "1                  0                        0                         0   \n",
      "2                  0                        0                         0   \n",
      "\n",
      "   Predicted Sentiment  \n",
      "0                Moana  \n",
      "1                Moana  \n",
      "2                Moana  \n",
      "\n",
      "[3 rows x 150 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data[col] = 0\n",
      "/var/folders/xp/ym_wbb515j9dqqd5lq230nb00000gn/T/ipykernel_94955/2849231380.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_script_data['Predicted Sentiment'] = new_predictions\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not convert string 'MoanaMoanaMoana' to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_script_data)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Step 11: Predict Overall Movie Sentiment\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Aggregate individual character sentiments to predict overall movie sentiment\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m overall_movie_sentiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPositive\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnew_script_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPredicted Sentiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegative\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPredicted Overall Movie Sentiment:\u001b[39m\u001b[38;5;124m\"\u001b[39m, overall_movie_sentiment)\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/core/series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   6548\u001b[0m ):\n\u001b[0;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/core/generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12421\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  12422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/core/generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[1;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/core/series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6452\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[1;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6456\u001b[0m     )\n\u001b[0;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    723\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/core/nanops.py:1701\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_float(x) \u001b[38;5;129;01mor\u001b[39;00m is_integer(x) \u001b[38;5;129;01mor\u001b[39;00m is_complex(x)):\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1700\u001b[0m         \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1703\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(x)\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert string 'MoanaMoanaMoana' to numeric"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 10: Predict Sentiment for New Data\n",
    "# Simulate a new dataset based on an upcoming movie script\n",
    "new_script_data = pd.DataFrame({\n",
    "    'Character Name': ['Hero', 'Villain', 'Sidekick'],\n",
    "    'Role': ['Protagonist', 'Antagonist', 'Comic Relief'],\n",
    "    'Screen Time (Minutes)': [60, 45, 30]\n",
    "})\n",
    "\n",
    "# Preprocess the new dataset\n",
    "new_script_data = pd.get_dummies(new_script_data)\n",
    "missing_cols = set(features.columns) - set(new_script_data.columns)\n",
    "for col in missing_cols:\n",
    "    new_script_data[col] = 0\n",
    "\n",
    "new_script_data = new_script_data[features.columns]\n",
    "\n",
    "# Predict sentiment for the new script\n",
    "new_predictions = model.predict(new_script_data)\n",
    "new_script_data['Predicted Sentiment'] = new_predictions\n",
    "\n",
    "# Display the predictions\n",
    "print(\"\\nPredicted Sentiment for New Characters:\")\n",
    "print(new_script_data)\n",
    "\n",
    "# Step 11: Predict Overall Movie Sentiment\n",
    "# Aggregate individual character sentiments to predict overall movie sentiment\n",
    "overall_movie_sentiment = 'Positive' if new_script_data['Predicted Sentiment'].mean() > 0.5 else 'Negative'\n",
    "print(\"\\nPredicted Overall Movie Sentiment:\", overall_movie_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
